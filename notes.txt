rax = 24066367755926
tsc_base = 1727869341               // nt_tsc_base?
minus_tsc_base = rax - tsc_base
scale = 1478983228                  // nt_scale?
scaled = minus_tsc_base * scale     // integer potentially greater than 64 bits in length
shifted = scaled >> 32
base = 9245068404755
plus_base = shifted + base


111100010010110011100011010110000000100001111101111010110110011100001011100

shiftL 1929 64 .|. 7429461933312129116                                              -- 75 bit integer

24064639886585 * 1478983228 = 35591198780119037196380                               -- scaled
11110001001  0110011100011010110000000100001111101111010110110011100001011100       -- 75 bit integer

35591198780119037196380 >> 32 = 8286721720387
0000000000000000000001111000100101100111000110101100000001000011                    -- shifted

8286721720387 + 9245068404755 = 17531790125142

xnu paths:
libsyscall/wrappers/mach_absolute_time.s
osfmk/x86_64/machine_routines_asm.s
osfmk/i386/rtclock.c
osfmk/i386/tsc.c

#define	SLOW_TSC_THRESHOLD	1000067800	/* if slower, nonzero shift required in nanotime() algorithm */

/*
 * Nanotime/mach_absolutime_time
 * -----------------------------
 * The timestamp counter (TSC) - which counts cpu clock cycles and can be read
 * efficiently by the kernel and in userspace - is the reference for all timing.
 * The cpu clock rate is platform-dependent and may stop or be reset when the
 * processor is napped/slept.  As a result, nanotime is the software abstraction
 * used to maintain a monotonic clock, adjusted from an outside reference as needed.
 *
 * The kernel maintains nanotime information recording:
 * 	- the ratio of tsc to nanoseconds
 *	  with this ratio expressed as a 32-bit scale and shift
 *	  (power of 2 divider);
 *	- { tsc_base, ns_base } pair of corresponding timestamps.
 *
 * The tuple {tsc_base, ns_base, scale, shift} is exported in the commpage
 * for the userspace nanotime routine to read.
 *
 * All of the routines which update the nanotime data are non-reentrant.  This must
 * be guaranteed by the caller.
 */

/*
 * uint64_t _rtc_nanotime_read(rtc_nanotime_t *rntp);
 *
 * This is the same as the commpage nanotime routine, except that it uses the
 * kernel internal "rtc_nanotime_info" data instead of the commpage data.
 * These two copies of data are kept in sync by rtc_clock_napped().
 *
 * Warning!  There are several copies of this code in the trampolines found in
 * osfmk/x86_64/idt64.s, coming from the various TIMER macros in rtclock_asm.h.
 * They're all kept in sync by using the RTC_NANOTIME_READ() macro.
 *
 * The algorithm we use is:
 *
 *	ns = ((((rdtsc - rnt_tsc_base)<<rnt_shift)*rnt_tsc_scale) / 2**32) + rnt_ns_base;
 *
 * rnt_shift, a constant computed during initialization, is the smallest value for which:
 *
 *	(tscFreq << rnt_shift) > SLOW_TSC_THRESHOLD
 *
 * Where SLOW_TSC_THRESHOLD is about 10e9.  Since most processor's tscFreqs are greater
 * than 1GHz, rnt_shift is usually 0.  rnt_tsc_scale is also a 32-bit constant:
 *
 *	rnt_tsc_scale = (10e9 * 2**32) / (tscFreq << rnt_shift);
 *
 * On 64-bit processors this algorithm could be simplified by doing a 64x64 bit
 * multiply of rdtsc by tscFCvtt2n:
 *
 *	ns = (((rdtsc - rnt_tsc_base) * tscFCvtt2n) / 2**32) + rnt_ns_base;
 *
 * We don't do so in order to use the same algorithm in 32- and 64-bit mode.
 * When U32 goes away, we should reconsider.
 *
 * Since this routine is not synchronized and can be called in any context,
 * we use a generation count to guard against seeing partially updated data.
 * In addition, the _rtc_nanotime_store() routine zeroes the generation before
 * updating the data, and stores the nonzero generation only after all fields
 * have been stored.  Because IA32 guarantees that stores by one processor
 * must be seen in order by another, we can avoid using a lock.  We spin while
 * the generation is zero.
 *
 * unint64_t _rtc_nanotime_read(
 *			rtc_nanotime_t *rntp);		// %rdi
 *
 */

/*
* SkyLake and later has an Always Running Timer (ART) providing
 * the reference frequency. CPUID leaf 0x15 determines the
 * rationship between this and the TSC frequency expressed as
 *   -	multiplier (numerator, N), and
 *   -	divisor (denominator, M).
 * So that TSC = ART * N / M.
 */

rdtsc
The time-stamp counter is a model-specific 64-bit counter that is reset to zero each time the processor is reset.
If not reset, the counter will increment ~9.5 x 1016 times per year when the processor is operating at a clock rate of 3GHz.
At this clock frequency, it would take over 190 years for the counter to wrap around. The RDTSC instruction loads the current
count of the time-stamp counter into the EDX:EAX registers.

To determine average processor clock frequency, Intel recommends the use of performance monitoring logic to count processor core
clocks over the period of time for which the average is required. See Section 18.6.4.5, “Counting Clocks on systems with Intel
Hyper-Threading Technology in Processors Based on Intel NetBurst® Microarchitecture,” and Chapter 19, “Performance Monitoring
Events,” for more information.

Invariant TSC feature flag
The time stamp counter in newer processors may support an enhancement, referred to as invariant TSC. Processor’s support for
invariant TSC is indicated by CPUID.80000007H:EDX[8].  The invariant TSC will run at a constant rate in all ACPI P-, C-. and
T-states. This is the architectural behavior moving forward. On processors with invariant TSC support, the OS may use the TSC
for wall clock timer services (instead of ACPI or HPET timers). TSC reads are much more efficient and do not incur the overhead
associated with a ring transition or access to a platform resource.

Invariant Time-Keeping
The invariant TSC is based on the invariant timekeeping hardware (called Always Running Timer or ART), that runs at the
core crystal clock frequency. The ratio defined by CPUID leaf 15H expresses the frequency relationship between the ART hardware
and TSC.
If CPUID.15H:EBX[31:0] != 0 and CPUID.80000007H:EDX[InvariantTSC] = 1, the following linearity relationship holds between TSC and
the ART hardware:

TSC_Value = (ART_Value * CPUID.15H:EBX[31:0] )/ CPUID.15H:EAX[31:0] + K

Where 'K' is an offset that can be adjusted by a privileged agent. When ART hardware is reset, both invariant TSC and K are also reset.

https://wiki.osdev.org/Timer_Interrupt_Sources
https://wiki.osdev.org/Detecting_CPU_Speed
